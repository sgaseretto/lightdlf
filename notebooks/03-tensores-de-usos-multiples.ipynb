{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Añadiendo la posibilidad de usar multiples veces el mismo tensor\n",
    "Como se vio al final del [notebook](02-intro-autograd.ipynb) anterior, si un tensor participa en la creacion de más de un tensor, su gradiente no se acumula, simplemente sobreescribe el gradiente con el ultimo gradiente recibido por el tensor. \n",
    "\n",
    "Para que un tensor pueda participar en la creacion de más de un tensor y mantener correctamente su gradiente es necesario añadir una nueva funcion y actualizar otras tres.\n",
    "\n",
    "Primero que nada los gradientes tienen que poder ser acumulables, permitiendo que si un tensor es usado más de una vez, pueda recibir el gradiente de todos sus hijos (tensores que se originan a partir de el).\n",
    "Adicionalmente se debe crear un contador que permite saber el número de gradientes recibidos por cada uno de los ```hijos``` o tensores creados a partir de los iniciales. Con este conteo también se previene retropropagar el gradiente del mismo hijo dos veces.\n",
    "\n",
    "También el método ```all_children_accounted_for()``` se utiiza para computar si un tensor recibió el gradiente de todos sus hijos en el grafo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Tensor(object):\n",
    "    \n",
    "    def __init__(self, data, \n",
    "                 autograd=False,\n",
    "                 creators=None,\n",
    "                 creation_op=None,\n",
    "                 id=None):\n",
    "        '''\n",
    "        Inicializa un tensor utilizando numpy\n",
    "        \n",
    "        @data: una lista de numeros\n",
    "        @creators: lista de tensores que participarion en la creacion de un nuevo tensor\n",
    "        @creators_op: la operacion utilizada para combinar los tensores en el nuevo tensor\n",
    "        '''\n",
    "        self.data = np.array(data)\n",
    "        self.creation_op = creation_op\n",
    "        self.creators = creators\n",
    "        self.grad = None\n",
    "        self.autograd = autograd\n",
    "        self.children = {}\n",
    "        # se asigna un id al tensor\n",
    "        if(id is None):\n",
    "            id = np.random.randint(0,100000)\n",
    "        self.id = id\n",
    "        \n",
    "        # se hace un seguimiento de cuantos hijos tiene un tensor\n",
    "        # si los creadores no es none\n",
    "        if (creators is not None):\n",
    "            # para cada tensor padre\n",
    "            for c in creators:\n",
    "                # se verifica si el tensor padre posee el id del tensor hijo\n",
    "                # en caso de no estar, agrega el id del tensor hijo al tensor padre\n",
    "                if(self.id not in c.children):\n",
    "                    c.children[self.id] = 1\n",
    "                # si el tensor ya se encuentra entre los hijos del padre\n",
    "                # y vuelve a aparece, se incrementa en uno\n",
    "                # la cantidad de apariciones del tensor hijo\n",
    "                else:\n",
    "                    c.children[self.id] += 1\n",
    "                    \n",
    "    def all_children_grads_accounted_for(self, tab='', print_call=True):\n",
    "        '''\n",
    "        Verifica si un tensor ha recibido la cantidad \n",
    "        correcta de gradientes por cada uno de sus hijos\n",
    "        '''\n",
    "        # print('tensor id:', self.id)\n",
    "        # print(tab+'all_children_grads_accounted_for({})'.format(self.id))\n",
    "        for id, cnt in self.children.items():\n",
    "            if (print_call) :\n",
    "                print(tab+'Tensor actual:', self.id, 'hijo:', id, 'count', cnt)\n",
    "            if(cnt != 0):\n",
    "                return False\n",
    "        return True\n",
    "        \n",
    "    def backward(self, grad, grad_origin=None, tab=''):\n",
    "        '''\n",
    "        Funcion que propaga recursivamente el gradiente a los creators o padres del tensor\n",
    "        \n",
    "        @grad: gradiente \n",
    "        @grad_orign\n",
    "        '''\n",
    "        # tab=tab\n",
    "        print(tab+'backward({}, {}, {})'.format(self.id, grad, grad_origin))\n",
    "        if(self.autograd):\n",
    "            if(grad_origin is not None):\n",
    "                print(tab+'El gradiente de',self.id,'proviene de (grad_origin):',grad_origin.id, 'count:', self.children[grad_origin.id])\n",
    "                # Verifica para asegurar si se puede hacer retropropagacion\n",
    "                if(self.children[grad_origin.id] == 0):\n",
    "                    raise Exception(\"No se puede retropropagar mas de una vez\")\n",
    "                # o si se está esperando un gradiente, en dicho caso se decrementa\n",
    "                else:\n",
    "                    # el contador para ese hijo\n",
    "                    self.children[grad_origin.id] -= 1\n",
    "                    print(tab+'por tanto el contador de',self.id,'se reduce a', self.children[grad_origin.id], 'para su hijo', grad_origin.id)\n",
    "        \n",
    "        # acumula el gradiente de multiples hijos\n",
    "        if(self.grad is None):\n",
    "            self.grad = grad\n",
    "        else:\n",
    "            self.grad += grad\n",
    "        \n",
    "        \n",
    "        print(tab+'Tensor', self.id, 'has creators?', self.creators is not None,\n",
    "              '\\n'+tab+'All children grads from', self.id,'accounted for is (cnt != 0)', self.all_children_grads_accounted_for(tab=tab, print_call=False),\n",
    "              '\\n'+tab+'Has grad origin?', grad_origin is None,\n",
    "              '\\n'+tab+'Has creators and (children grads accounted or grad no grad origin)',\n",
    "              '\\n'+tab, self.creators is not None, 'and', '(',self.all_children_grads_accounted_for(print_call=False) ,'or',grad_origin is None,') =>',\n",
    "              self.creators is not None and (self.all_children_grads_accounted_for(print_call=False) or grad_origin is None)\n",
    "             )\n",
    "        if(self.creators is not None and\n",
    "          (self.all_children_grads_accounted_for(print_call=False) or grad_origin is None)):\n",
    "            \n",
    "            if (self.creation_op == 'add'):\n",
    "                # al recibir self.grad, empieza a realizar backprop\n",
    "                print(tab + str(self.id), 'creators are:')\n",
    "                print(tab+'creator', self.creators[0].id, ':', self.creators[0], \n",
    "                      'creator', self.creators[1].id, ':',self.creators[1])\n",
    "                print(tab+'\\tbackward call from creator[0]:', self.creators[0].id)\n",
    "                self.creators[0].backward(self.grad, grad_origin=self, tab=tab+'\\t')\n",
    "                print()\n",
    "                print(tab+'\\tbackward call from creator[1]', self.creators[0].id)\n",
    "                self.creators[1].backward(self.grad, grad_origin=self, tab=tab+'\\t')\n",
    "                \n",
    "        \n",
    "    def __add__(self, other):\n",
    "        '''\n",
    "        @other: un Tensor\n",
    "        '''\n",
    "        if(self.autograd and other.autograd):\n",
    "            new_tensor = Tensor(self.data + other.data, \n",
    "                                autograd=True,\n",
    "                                creators=[self, other],\n",
    "                                creation_op='add')\n",
    "            print('  new tensor id is', new_tensor.id)\n",
    "            return new_tensor\n",
    "        return Tensor(self.data + other.data)\n",
    "    \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.data.__repr__())\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.data.__str__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizacion de las llamadas de backward\n",
    "Se agrego al metodo backward una serie de ```print()```s que permiten ver las llamadas a medida que se propaga el gradiente por cada uno de los tensores que participaron en la creación del tensor final, es decir la salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = x + x\n",
      "  new tensor id is 5092\n",
      "z = y + y\n",
      "  new tensor id is 93566\n",
      "\n",
      "x id: 61277\n",
      " hijo: 5092 count 2\n",
      "y id: 5092\n",
      " hijo: 93566 count 2\n",
      "z id: 93566 \n",
      "\n",
      "backward(93566, [1 1 1 1], None)\n",
      "Tensor 93566 has creators? True \n",
      "All children grads from 93566 accounted for is (cnt != 0) True \n",
      "Has grad origin? True \n",
      "Has creators and (children grads accounted or grad no grad origin) \n",
      " True and ( True or True ) => True\n",
      "93566 creators are:\n",
      "creator 5092 : [4 4 4 4] creator 5092 : [4 4 4 4]\n",
      "\tbackward call from creator[0]: 5092\n",
      "\tbackward(5092, [1 1 1 1], [8 8 8 8])\n",
      "\tEl gradiente de 5092 proviene de (grad_origin): 93566 count: 2\n",
      "\tpor tanto el contador de 5092 se reduce a 1 para su hijo 93566\n",
      "\tTensor 5092 has creators? True \n",
      "\tAll children grads from 5092 accounted for is (cnt != 0) False \n",
      "\tHas grad origin? False \n",
      "\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t True and ( False or False ) => False\n",
      "\n",
      "\tbackward call from creator[1] 5092\n",
      "\tbackward(5092, [1 1 1 1], [8 8 8 8])\n",
      "\tEl gradiente de 5092 proviene de (grad_origin): 93566 count: 1\n",
      "\tpor tanto el contador de 5092 se reduce a 0 para su hijo 93566\n",
      "\tTensor 5092 has creators? True \n",
      "\tAll children grads from 5092 accounted for is (cnt != 0) True \n",
      "\tHas grad origin? False \n",
      "\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t True and ( True or False ) => True\n",
      "\t5092 creators are:\n",
      "\tcreator 61277 : [2 2 2 2] creator 61277 : [2 2 2 2]\n",
      "\t\tbackward call from creator[0]: 61277\n",
      "\t\tbackward(61277, [2 2 2 2], [4 4 4 4])\n",
      "\t\tEl gradiente de 61277 proviene de (grad_origin): 5092 count: 2\n",
      "\t\tpor tanto el contador de 61277 se reduce a 1 para su hijo 5092\n",
      "\t\tTensor 61277 has creators? False \n",
      "\t\tAll children grads from 61277 accounted for is (cnt != 0) False \n",
      "\t\tHas grad origin? False \n",
      "\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t False and ( False or False ) => False\n",
      "\n",
      "\t\tbackward call from creator[1] 61277\n",
      "\t\tbackward(61277, [2 2 2 2], [4 4 4 4])\n",
      "\t\tEl gradiente de 61277 proviene de (grad_origin): 5092 count: 1\n",
      "\t\tpor tanto el contador de 61277 se reduce a 0 para su hijo 5092\n",
      "\t\tTensor 61277 has creators? False \n",
      "\t\tAll children grads from 61277 accounted for is (cnt != 0) True \n",
      "\t\tHas grad origin? False \n",
      "\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t False and ( True or False ) => False\n",
      "\n",
      "x gradient data: [4 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "x = Tensor([2,2,2,2], autograd=True)\n",
    "print('y = x + x')\n",
    "y = x + x\n",
    "print('z = y + y')\n",
    "z = y + y\n",
    "print()\n",
    "\n",
    "print('x id:',x.id)\n",
    "for hijo, cnt in x.children.items():\n",
    "    print(' hijo:', hijo, 'count', cnt)\n",
    "    \n",
    "print('y id:', y.id)\n",
    "for hijo, cnt in y.children.items():\n",
    "    print(' hijo:', hijo, 'count', cnt)\n",
    "    \n",
    "print('z id:', z.id, '\\n')\n",
    "z.backward(Tensor([1,1,1,1]))\n",
    "print('\\nx gradient data:',x.grad.data)\n",
    "# z.backward(Tensor([1,1,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d = a + b\n",
      "  new tensor id is 40347\n",
      "e = b + c\n",
      "  new tensor id is 94654\n",
      "f = d + e\n",
      "  new tensor id is 38534\n",
      "\n",
      "a id: 67889\n",
      "\thijo: 40347 count 1\n",
      "b id: 64480\n",
      "\thijo: 40347 count 1\n",
      "\thijo: 94654 count 1\n",
      "c id: 60234\n",
      "\thijo: 94654 count 1\n",
      "d id: 40347\n",
      "\thijo: 38534 count 1\n",
      "e id: 94654\n",
      "\thijo: 38534 count 1\n",
      "f id: 38534 \n",
      "\n",
      "backward(38534, [1 1 1 1 1], None)\n",
      "all_children_grads_accounted_for(38534)\n",
      "all_children_grads_accounted_for(38534)\n",
      "all_children_grads_accounted_for(38534)\n",
      "Tensor 38534 has creators? True \n",
      "All children grads from 38534 accounted for is (cnt != 0) True \n",
      "Has grad origin? True \n",
      "Has creators and (children grads accounted or grad no grad origin) \n",
      " True and ( True or True ) => True\n",
      "all_children_grads_accounted_for(38534)\n",
      "38534 creators are:\n",
      "creator 40347 : [3 4 5 6 7] creator 94654 : [7 6 5 4 3]\n",
      "\tbackward call from creator[0]: 40347\n",
      "\tbackward(40347, [1 1 1 1 1], [10 10 10 10 10])\n",
      "\tEl gradiente de 40347 proviene de (grad_origin): 38534 count: 1\n",
      "\tpor tanto el contador de 40347 se reduce a 0 para su hijo 38534\n",
      "\tall_children_grads_accounted_for(40347)\n",
      "all_children_grads_accounted_for(40347)\n",
      "all_children_grads_accounted_for(40347)\n",
      "\tTensor 40347 has creators? True \n",
      "\tAll children grads from 40347 accounted for is (cnt != 0) True \n",
      "\tHas grad origin? False \n",
      "\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t True and ( True or False ) => True\n",
      "all_children_grads_accounted_for(40347)\n",
      "\t40347 creators are:\n",
      "\tcreator 67889 : [1 2 3 4 5] creator 64480 : [2 2 2 2 2]\n",
      "\t\tbackward call from creator[0]: 67889\n",
      "\t\tbackward(67889, [1 1 1 1 1], [3 4 5 6 7])\n",
      "\t\tEl gradiente de 67889 proviene de (grad_origin): 40347 count: 1\n",
      "\t\tpor tanto el contador de 67889 se reduce a 0 para su hijo 40347\n",
      "\t\tall_children_grads_accounted_for(67889)\n",
      "all_children_grads_accounted_for(67889)\n",
      "\t\tTensor 67889 has creators? False \n",
      "\t\tAll children grads from 67889 accounted for is (cnt != 0) True \n",
      "\t\tHas grad origin? False \n",
      "\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t False and ( True or False ) => False\n",
      "\n",
      "\t\tbackward call from creator[1] 67889\n",
      "\t\tbackward(64480, [1 1 1 1 1], [3 4 5 6 7])\n",
      "\t\tEl gradiente de 64480 proviene de (grad_origin): 40347 count: 1\n",
      "\t\tpor tanto el contador de 64480 se reduce a 0 para su hijo 40347\n",
      "\t\tall_children_grads_accounted_for(64480)\n",
      "all_children_grads_accounted_for(64480)\n",
      "\t\tTensor 64480 has creators? False \n",
      "\t\tAll children grads from 64480 accounted for is (cnt != 0) False \n",
      "\t\tHas grad origin? False \n",
      "\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t False and ( False or False ) => False\n",
      "\n",
      "\tbackward call from creator[1] 40347\n",
      "\tbackward(94654, [1 1 1 1 1], [10 10 10 10 10])\n",
      "\tEl gradiente de 94654 proviene de (grad_origin): 38534 count: 1\n",
      "\tpor tanto el contador de 94654 se reduce a 0 para su hijo 38534\n",
      "\tall_children_grads_accounted_for(94654)\n",
      "all_children_grads_accounted_for(94654)\n",
      "all_children_grads_accounted_for(94654)\n",
      "\tTensor 94654 has creators? True \n",
      "\tAll children grads from 94654 accounted for is (cnt != 0) True \n",
      "\tHas grad origin? False \n",
      "\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t True and ( True or False ) => True\n",
      "all_children_grads_accounted_for(94654)\n",
      "\t94654 creators are:\n",
      "\tcreator 64480 : [2 2 2 2 2] creator 60234 : [5 4 3 2 1]\n",
      "\t\tbackward call from creator[0]: 64480\n",
      "\t\tbackward(64480, [1 1 1 1 1], [7 6 5 4 3])\n",
      "\t\tEl gradiente de 64480 proviene de (grad_origin): 94654 count: 1\n",
      "\t\tpor tanto el contador de 64480 se reduce a 0 para su hijo 94654\n",
      "\t\tall_children_grads_accounted_for(64480)\n",
      "all_children_grads_accounted_for(64480)\n",
      "\t\tTensor 64480 has creators? False \n",
      "\t\tAll children grads from 64480 accounted for is (cnt != 0) True \n",
      "\t\tHas grad origin? False \n",
      "\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t False and ( True or False ) => False\n",
      "\n",
      "\t\tbackward call from creator[1] 64480\n",
      "\t\tbackward(60234, [1 1 1 1 1], [7 6 5 4 3])\n",
      "\t\tEl gradiente de 60234 proviene de (grad_origin): 94654 count: 1\n",
      "\t\tpor tanto el contador de 60234 se reduce a 0 para su hijo 94654\n",
      "\t\tall_children_grads_accounted_for(60234)\n",
      "all_children_grads_accounted_for(60234)\n",
      "\t\tTensor 60234 has creators? False \n",
      "\t\tAll children grads from 60234 accounted for is (cnt != 0) True \n",
      "\t\tHas grad origin? False \n",
      "\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t False and ( True or False ) => False\n",
      "[ True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "a = Tensor([1,2,3,4,5], autograd=True)\n",
    "b = Tensor([2,2,2,2,2], autograd=True)\n",
    "c = Tensor([5,4,3,2,1], autograd=True)\n",
    "\n",
    "print('d = a + b')\n",
    "d = a + b\n",
    "print('e = b + c')\n",
    "e = b + c\n",
    "print('f = d + e')\n",
    "f = d + e\n",
    "print()\n",
    "\n",
    "print('a id:',a.id)\n",
    "for hijo, cnt in a.children.items():\n",
    "    print('\\thijo:', hijo, 'count', cnt)\n",
    "    \n",
    "print('b id:', b.id)\n",
    "for hijo, cnt in b.children.items():\n",
    "    print('\\thijo:', hijo, 'count', cnt)\n",
    "    \n",
    "print('c id:',c.id)\n",
    "for hijo, cnt in c.children.items():\n",
    "    print('\\thijo:', hijo, 'count', cnt)\n",
    "    \n",
    "print('d id:', d.id)\n",
    "for hijo, cnt in d.children.items():\n",
    "    print('\\thijo:', hijo, 'count', cnt)\n",
    "\n",
    "print('e id:', e.id)\n",
    "for hijo, cnt in e.children.items():\n",
    "    print('\\thijo:', hijo, 'count', cnt)\n",
    "    \n",
    "print('f id:', f.id, '\\n')\n",
    "\n",
    "f.backward(Tensor(np.array([1,1,1,1,1])))\n",
    "print(b.grad.data == np.array([2,2,2,2,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x3 = x1 + x2\n",
      "  new tensor id is 30107\n",
      "x4 = x1 + x2\n",
      "  new tensor id is 57918\n",
      "x5 = x1+ x2 + x3 + x4\n",
      "  new tensor id is 23724\n",
      "  new tensor id is 36893\n",
      "  new tensor id is 92965\n",
      "\n",
      "x1 id: 62923\n",
      "\thijo: 30107 count 1\n",
      "\thijo: 57918 count 1\n",
      "\thijo: 23724 count 1\n",
      "x2 id: 36195\n",
      "\thijo: 30107 count 1\n",
      "\thijo: 57918 count 1\n",
      "\thijo: 23724 count 1\n",
      "x3 id: 30107\n",
      "\thijo: 36893 count 1\n",
      "x4 id: 57918\n",
      "\thijo: 92965 count 1\n",
      "x5 id: 92965 \n",
      "\n",
      "Tensor 92965 has creators? True \n",
      "All children grads from 92965 accounted for is (cnt != 0) True \n",
      "Has grad origin? True \n",
      "Has creators and (children grads accounted or grad no grad origin) \n",
      " True and ( True or True ) => True\n",
      "92965 creators are:\n",
      "creator 36893 : [4 4 4 4] creator 57918 : [2 2 2 2]\n",
      "\tbackward call from creator[0]: 36893\n",
      "\tEl gradiente de 36893 proviene de (grad_origin): 92965 count: 1\n",
      "\tpor tanto el contador de 36893 se reduce a 0 para su hijo 92965\n",
      "\tTensor 36893 has creators? True \n",
      "\tAll children grads from 36893 accounted for is (cnt != 0) True \n",
      "\tHas grad origin? False \n",
      "\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t True and ( True or False ) => True\n",
      "\t36893 creators are:\n",
      "\tcreator 23724 : [2 2 2 2] creator 30107 : [2 2 2 2]\n",
      "\t\tbackward call from creator[0]: 23724\n",
      "\t\tEl gradiente de 23724 proviene de (grad_origin): 36893 count: 1\n",
      "\t\tpor tanto el contador de 23724 se reduce a 0 para su hijo 36893\n",
      "\t\tTensor 23724 has creators? True \n",
      "\t\tAll children grads from 23724 accounted for is (cnt != 0) True \n",
      "\t\tHas grad origin? False \n",
      "\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t True and ( True or False ) => True\n",
      "\t\t23724 creators are:\n",
      "\t\tcreator 62923 : [1 1 1 1] creator 36195 : [1 1 1 1]\n",
      "\t\t\tbackward call from creator[0]: 62923\n",
      "\t\t\tEl gradiente de 62923 proviene de (grad_origin): 23724 count: 1\n",
      "\t\t\tpor tanto el contador de 62923 se reduce a 0 para su hijo 23724\n",
      "\t\t\tTensor 62923 has creators? False \n",
      "\t\t\tAll children grads from 62923 accounted for is (cnt != 0) False \n",
      "\t\t\tHas grad origin? False \n",
      "\t\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t\t False and ( False or False ) => False\n",
      "\n",
      "\t\t\tbackward call from creator[1] 62923\n",
      "\t\t\tEl gradiente de 36195 proviene de (grad_origin): 23724 count: 1\n",
      "\t\t\tpor tanto el contador de 36195 se reduce a 0 para su hijo 23724\n",
      "\t\t\tTensor 36195 has creators? False \n",
      "\t\t\tAll children grads from 36195 accounted for is (cnt != 0) False \n",
      "\t\t\tHas grad origin? False \n",
      "\t\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t\t False and ( False or False ) => False\n",
      "\n",
      "\t\tbackward call from creator[1] 23724\n",
      "\t\tEl gradiente de 30107 proviene de (grad_origin): 36893 count: 1\n",
      "\t\tpor tanto el contador de 30107 se reduce a 0 para su hijo 36893\n",
      "\t\tTensor 30107 has creators? True \n",
      "\t\tAll children grads from 30107 accounted for is (cnt != 0) True \n",
      "\t\tHas grad origin? False \n",
      "\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t True and ( True or False ) => True\n",
      "\t\t30107 creators are:\n",
      "\t\tcreator 62923 : [1 1 1 1] creator 36195 : [1 1 1 1]\n",
      "\t\t\tbackward call from creator[0]: 62923\n",
      "\t\t\tEl gradiente de 62923 proviene de (grad_origin): 30107 count: 1\n",
      "\t\t\tpor tanto el contador de 62923 se reduce a 0 para su hijo 30107\n",
      "\t\t\tTensor 62923 has creators? False \n",
      "\t\t\tAll children grads from 62923 accounted for is (cnt != 0) False \n",
      "\t\t\tHas grad origin? False \n",
      "\t\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t\t False and ( False or False ) => False\n",
      "\n",
      "\t\t\tbackward call from creator[1] 62923\n",
      "\t\t\tEl gradiente de 36195 proviene de (grad_origin): 30107 count: 1\n",
      "\t\t\tpor tanto el contador de 36195 se reduce a 0 para su hijo 30107\n",
      "\t\t\tTensor 36195 has creators? False \n",
      "\t\t\tAll children grads from 36195 accounted for is (cnt != 0) False \n",
      "\t\t\tHas grad origin? False \n",
      "\t\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t\t False and ( False or False ) => False\n",
      "\n",
      "\tbackward call from creator[1] 36893\n",
      "\tEl gradiente de 57918 proviene de (grad_origin): 92965 count: 1\n",
      "\tpor tanto el contador de 57918 se reduce a 0 para su hijo 92965\n",
      "\tTensor 57918 has creators? True \n",
      "\tAll children grads from 57918 accounted for is (cnt != 0) True \n",
      "\tHas grad origin? False \n",
      "\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t True and ( True or False ) => True\n",
      "\t57918 creators are:\n",
      "\tcreator 62923 : [1 1 1 1] creator 36195 : [1 1 1 1]\n",
      "\t\tbackward call from creator[0]: 62923\n",
      "\t\tEl gradiente de 62923 proviene de (grad_origin): 57918 count: 1\n",
      "\t\tpor tanto el contador de 62923 se reduce a 0 para su hijo 57918\n",
      "\t\tTensor 62923 has creators? False \n",
      "\t\tAll children grads from 62923 accounted for is (cnt != 0) True \n",
      "\t\tHas grad origin? False \n",
      "\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t False and ( True or False ) => False\n",
      "\n",
      "\t\tbackward call from creator[1] 62923\n",
      "\t\tEl gradiente de 36195 proviene de (grad_origin): 57918 count: 1\n",
      "\t\tpor tanto el contador de 36195 se reduce a 0 para su hijo 57918\n",
      "\t\tTensor 36195 has creators? False \n",
      "\t\tAll children grads from 36195 accounted for is (cnt != 0) True \n",
      "\t\tHas grad origin? False \n",
      "\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t False and ( True or False ) => False\n"
     ]
    }
   ],
   "source": [
    "x1 = Tensor([1,1,1,1], autograd=True)\n",
    "x2 = Tensor([1,1,1,1], autograd=True)\n",
    "\n",
    "print('x3 = x1 + x2')\n",
    "x3 = x1 + x2\n",
    "print('x4 = x1 + x2')\n",
    "x4 = x1 + x2\n",
    "print('x5 = x1+ x2 + x3 + x4')\n",
    "x5 = x1+ x2 + x3 + x4\n",
    "print()\n",
    "\n",
    "print('x1 id:',x1.id)\n",
    "for hijo, cnt in x1.children.items():\n",
    "    print('\\thijo:', hijo, 'count', cnt)\n",
    "    \n",
    "print('x2 id:', x2.id)\n",
    "for hijo, cnt in x2.children.items():\n",
    "    print('\\thijo:', hijo, 'count', cnt)\n",
    "    \n",
    "print('x3 id:',x3.id)\n",
    "for hijo, cnt in x3.children.items():\n",
    "    print('\\thijo:', hijo, 'count', cnt)\n",
    "    \n",
    "print('x4 id:', x4.id)\n",
    "for hijo, cnt in x4.children.items():\n",
    "    print('\\thijo:', hijo, 'count', cnt)\n",
    "    \n",
    "print('x5 id:', x5.id, '\\n')\n",
    "\n",
    "x5.backward(Tensor([1,1,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = x + x + x + x\n",
      "  new tensor id is 40681\n",
      "  new tensor id is 10062\n",
      "  new tensor id is 60762\n",
      "z = y + y\n",
      "  new tensor id is 51449\n",
      "\n",
      "x id: 21051\n",
      " hijo: 40681 count 2\n",
      " hijo: 10062 count 1\n",
      " hijo: 60762 count 1\n",
      "y id: 60762\n",
      " hijo: 51449 count 2\n",
      "z id: 51449 \n",
      "\n",
      "Tensor 51449 has creators? True \n",
      "All children grads from 51449 accounted for is (cnt != 0) True \n",
      "Has grad origin? True \n",
      "Has creators and (children grads accounted or grad no grad origin) \n",
      " True and ( True or True ) => True\n",
      "51449 creators are:\n",
      "creator 60762 : [8 8 8 8] creator 60762 : [8 8 8 8]\n",
      "\tbackward call from creator[0]: 60762\n",
      "\tEl gradiente de 60762 proviene de (grad_origin): 51449 count: 2\n",
      "\tpor tanto el contador de 60762 se reduce a 1 para su hijo 51449\n",
      "\tTensor 60762 has creators? True \n",
      "\tAll children grads from 60762 accounted for is (cnt != 0) False \n",
      "\tHas grad origin? False \n",
      "\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t True and ( False or False ) => False\n",
      "\n",
      "\tbackward call from creator[1] 60762\n",
      "\tEl gradiente de 60762 proviene de (grad_origin): 51449 count: 1\n",
      "\tpor tanto el contador de 60762 se reduce a 0 para su hijo 51449\n",
      "\tTensor 60762 has creators? True \n",
      "\tAll children grads from 60762 accounted for is (cnt != 0) True \n",
      "\tHas grad origin? False \n",
      "\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t True and ( True or False ) => True\n",
      "\t60762 creators are:\n",
      "\tcreator 10062 : [6 6 6 6] creator 21051 : [2 2 2 2]\n",
      "\t\tbackward call from creator[0]: 10062\n",
      "\t\tEl gradiente de 10062 proviene de (grad_origin): 60762 count: 1\n",
      "\t\tpor tanto el contador de 10062 se reduce a 0 para su hijo 60762\n",
      "\t\tTensor 10062 has creators? True \n",
      "\t\tAll children grads from 10062 accounted for is (cnt != 0) True \n",
      "\t\tHas grad origin? False \n",
      "\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t True and ( True or False ) => True\n",
      "\t\t10062 creators are:\n",
      "\t\tcreator 40681 : [4 4 4 4] creator 21051 : [2 2 2 2]\n",
      "\t\t\tbackward call from creator[0]: 40681\n",
      "\t\t\tEl gradiente de 40681 proviene de (grad_origin): 10062 count: 1\n",
      "\t\t\tpor tanto el contador de 40681 se reduce a 0 para su hijo 10062\n",
      "\t\t\tTensor 40681 has creators? True \n",
      "\t\t\tAll children grads from 40681 accounted for is (cnt != 0) True \n",
      "\t\t\tHas grad origin? False \n",
      "\t\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t\t True and ( True or False ) => True\n",
      "\t\t\t40681 creators are:\n",
      "\t\t\tcreator 21051 : [2 2 2 2] creator 21051 : [2 2 2 2]\n",
      "\t\t\t\tbackward call from creator[0]: 21051\n",
      "\t\t\t\tEl gradiente de 21051 proviene de (grad_origin): 40681 count: 2\n",
      "\t\t\t\tpor tanto el contador de 21051 se reduce a 1 para su hijo 40681\n",
      "\t\t\t\tTensor 21051 has creators? False \n",
      "\t\t\t\tAll children grads from 21051 accounted for is (cnt != 0) False \n",
      "\t\t\t\tHas grad origin? False \n",
      "\t\t\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t\t\t False and ( False or False ) => False\n",
      "\n",
      "\t\t\t\tbackward call from creator[1] 21051\n",
      "\t\t\t\tEl gradiente de 21051 proviene de (grad_origin): 40681 count: 1\n",
      "\t\t\t\tpor tanto el contador de 21051 se reduce a 0 para su hijo 40681\n",
      "\t\t\t\tTensor 21051 has creators? False \n",
      "\t\t\t\tAll children grads from 21051 accounted for is (cnt != 0) False \n",
      "\t\t\t\tHas grad origin? False \n",
      "\t\t\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t\t\t False and ( False or False ) => False\n",
      "\n",
      "\t\t\tbackward call from creator[1] 40681\n",
      "\t\t\tEl gradiente de 21051 proviene de (grad_origin): 10062 count: 1\n",
      "\t\t\tpor tanto el contador de 21051 se reduce a 0 para su hijo 10062\n",
      "\t\t\tTensor 21051 has creators? False \n",
      "\t\t\tAll children grads from 21051 accounted for is (cnt != 0) False \n",
      "\t\t\tHas grad origin? False \n",
      "\t\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t\t False and ( False or False ) => False\n",
      "\n",
      "\t\tbackward call from creator[1] 10062\n",
      "\t\tEl gradiente de 21051 proviene de (grad_origin): 60762 count: 1\n",
      "\t\tpor tanto el contador de 21051 se reduce a 0 para su hijo 60762\n",
      "\t\tTensor 21051 has creators? False \n",
      "\t\tAll children grads from 21051 accounted for is (cnt != 0) True \n",
      "\t\tHas grad origin? False \n",
      "\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t False and ( True or False ) => False\n",
      "\n",
      "x gradient data: [8 8 8 8]\n"
     ]
    }
   ],
   "source": [
    "x = Tensor([2,2,2,2], autograd=True)\n",
    "\n",
    "print('y = x + x + x + x')\n",
    "y = x + x + x + x\n",
    "print('z = y + y')\n",
    "z = y + y\n",
    "print()\n",
    "\n",
    "print('x id:',x.id)\n",
    "for hijo, cnt in x.children.items():\n",
    "    print(' hijo:', hijo, 'count', cnt)\n",
    "    \n",
    "print('y id:', y.id)\n",
    "for hijo, cnt in y.children.items():\n",
    "    print(' hijo:', hijo, 'count', cnt)\n",
    "    \n",
    "print('z id:', z.id, '\\n')\n",
    "\n",
    "z.backward(Tensor([1,1,1,1]))\n",
    "print('\\nx gradient data:',x.grad.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
