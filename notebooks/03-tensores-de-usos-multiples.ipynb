{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Añadiendo la posibilidad de usar multiples veces el mismo tensor\n",
    "Como se vio al final del [notebook](02-intro-autograd.ipynb) anterior, si un tensor participa en la creacion de más de un tensor, su gradiente no se acumula, simplemente sobreescribe el gradiente con el ultimo gradiente recibido por el tensor. \n",
    "\n",
    "Para que un tensor pueda participar en la creacion de más de un tensor y mantener correctamente su gradiente es necesario añadir una nueva funcion y actualizar otras tres.\n",
    "\n",
    "Primero que nada los gradientes tienen que poder ser acumulables, permitiendo que si un tensor es usado más de una vez, pueda recibir el gradiente de todos sus hijos (tensores que se originan a partir de el).\n",
    "Adicionalmente se debe crear un contador que permite saber el número de gradientes recibidos por cada uno de los ```hijos``` o tensores creados a partir de los iniciales. Con este conteo también se previene retropropagar el gradiente del mismo hijo dos veces.\n",
    "\n",
    "También el método ```all_children_accounted_for()``` se utiiza para computar si un tensor recibió el gradiente de todos sus hijos en el grafo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Tensor(object):\n",
    "    \n",
    "    def __init__(self, data, \n",
    "                 autograd=False,\n",
    "                 creators=None,\n",
    "                 creation_op=None,\n",
    "                 id=None):\n",
    "        '''\n",
    "        Inicializa un tensor utilizando numpy\n",
    "        \n",
    "        @data: una lista de numeros\n",
    "        @creators: lista de tensores que participarion en la creacion de un nuevo tensor\n",
    "        @creators_op: la operacion utilizada para combinar los tensores en el nuevo tensor\n",
    "        '''\n",
    "        self.data = np.array(data)\n",
    "        self.creation_op = creation_op\n",
    "        self.creators = creators\n",
    "        self.grad = None\n",
    "        self.autograd = autograd\n",
    "        self.children = {}\n",
    "        # se asigna un id al tensor\n",
    "        if(id is None):\n",
    "            id = np.random.randint(0,100000)\n",
    "        self.id = id\n",
    "        \n",
    "        # se hace un seguimiento de cuantos hijos tiene un tensor\n",
    "        # si los creadores no es none\n",
    "        if (creators is not None):\n",
    "            # para cada tensor padre\n",
    "            for c in creators:\n",
    "                # se verifica si el tensor padre posee el id del tensor hijo\n",
    "                # en caso de no estar, agrega el id del tensor hijo al tensor padre\n",
    "                if(self.id not in c.children):\n",
    "                    c.children[self.id] = 1\n",
    "                # si el tensor ya se encuentra entre los hijos del padre\n",
    "                # y vuelve a aparece, se incrementa en uno\n",
    "                # la cantidad de apariciones del tensor hijo\n",
    "                else:\n",
    "                    c.children[self.id] += 1\n",
    "                    \n",
    "    def all_children_grads_accounted_for(self, tab='', print_call=True):\n",
    "        '''\n",
    "        Verifica si un tensor ha recibido la cantidad \n",
    "        correcta de gradientes por cada uno de sus hijos\n",
    "        '''\n",
    "        # print('tensor id:', self.id)\n",
    "        # print(tab+'all_children_grads_accounted_for({})'.format(self.id))\n",
    "        for id, cnt in self.children.items():\n",
    "            if (print_call) :\n",
    "                print(tab+'Tensor actual:', self.id, 'hijo:', id, 'count', cnt)\n",
    "            if(cnt != 0):\n",
    "                return False\n",
    "        return True\n",
    "        \n",
    "    def backward(self, grad, grad_origin=None, tab=''):\n",
    "        '''\n",
    "        Funcion que propaga recursivamente el gradiente a los creators o padres del tensor\n",
    "        \n",
    "        @grad: gradiente \n",
    "        @grad_orign\n",
    "        '''\n",
    "        # tab=tab\n",
    "        print(tab+'backward({}, {}, {})'.format(self.id, grad, grad_origin))\n",
    "        if(self.autograd):\n",
    "            if(grad_origin is not None):\n",
    "                print(tab+'El gradiente de',self.id,'proviene de (grad_origin):',grad_origin.id, 'count:', self.children[grad_origin.id])\n",
    "                # Verifica para asegurar si se puede hacer retropropagacion\n",
    "                if(self.children[grad_origin.id] == 0):\n",
    "                    raise Exception(\"No se puede retropropagar mas de una vez\")\n",
    "                # o si se está esperando un gradiente, en dicho caso se decrementa\n",
    "                else:\n",
    "                    # el contador para ese hijo\n",
    "                    self.children[grad_origin.id] -= 1\n",
    "                    print(tab+'por tanto el contador de',self.id,'se reduce a', self.children[grad_origin.id], 'para su hijo', grad_origin.id)\n",
    "        \n",
    "        # acumula el gradiente de multiples hijos\n",
    "        if(self.grad is None):\n",
    "            self.grad = grad\n",
    "        else:\n",
    "            self.grad += grad\n",
    "        \n",
    "        \n",
    "        print(tab+'Tensor', self.id, 'has creators?', self.creators is not None,\n",
    "              '\\n'+tab+'All children grads from', self.id,'accounted for is (cnt != 0)', self.all_children_grads_accounted_for(tab=tab, print_call=False),\n",
    "              '\\n'+tab+'Has grad origin?', grad_origin is None,\n",
    "              '\\n'+tab+'Has creators and (children grads accounted or grad no grad origin)',\n",
    "              '\\n'+tab, self.creators is not None, 'and', '(',self.all_children_grads_accounted_for(print_call=False) ,'or',grad_origin is None,') =>',\n",
    "              self.creators is not None and (self.all_children_grads_accounted_for(print_call=False) or grad_origin is None)\n",
    "             )\n",
    "        if(self.creators is not None and\n",
    "          (self.all_children_grads_accounted_for(print_call=False) or grad_origin is None)):\n",
    "            \n",
    "            if (self.creation_op == 'add'):\n",
    "                # al recibir self.grad, empieza a realizar backprop\n",
    "                print(tab + str(self.id), 'creators are:')\n",
    "                print(tab+'creator', self.creators[0].id, ':', self.creators[0], \n",
    "                      'creator', self.creators[1].id, ':',self.creators[1])\n",
    "                print(tab+'\\tbackward call from creator[0]:', self.creators[0].id)\n",
    "                self.creators[0].backward(self.grad, grad_origin=self, tab=tab+'\\t')\n",
    "                print()\n",
    "                print(tab+'\\tbackward call from creator[1]', self.creators[0].id)\n",
    "                self.creators[1].backward(self.grad, grad_origin=self, tab=tab+'\\t')\n",
    "                \n",
    "        \n",
    "    def __add__(self, other):\n",
    "        '''\n",
    "        @other: un Tensor\n",
    "        '''\n",
    "        if(self.autograd and other.autograd):\n",
    "            new_tensor = Tensor(self.data + other.data, \n",
    "                                autograd=True,\n",
    "                                creators=[self, other],\n",
    "                                creation_op='add')\n",
    "            print('  new tensor id is', new_tensor.id)\n",
    "            return new_tensor\n",
    "        return Tensor(self.data + other.data)\n",
    "    \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.data.__repr__())\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.data.__str__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizacion de las llamadas de backward\n",
    "Se agrego al metodo backward una serie de ```print()```s que permiten ver las llamadas a medida que se propaga el gradiente por cada uno de los tensores que participaron en la creación del tensor final, es decir la salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = x + x\n",
      "  new tensor id is 36485\n",
      "z = y + y\n",
      "  new tensor id is 39106\n",
      "\n",
      "x id: 35424\n",
      " hijo: 36485 count 2\n",
      "y id: 36485\n",
      " hijo: 39106 count 2\n",
      "z id: 39106 \n",
      "\n",
      "backward(39106, [1 1 1 1], None)\n",
      "Tensor 39106 has creators? True \n",
      "All children grads from 39106 accounted for is (cnt != 0) True \n",
      "Has grad origin? True \n",
      "Has creators and (children grads accounted or grad no grad origin) \n",
      " True and ( True or True ) => True\n",
      "39106 creators are:\n",
      "creator 36485 : [4 4 4 4] creator 36485 : [4 4 4 4]\n",
      "\tbackward call from creator[0]: 36485\n",
      "\tbackward(36485, [1 1 1 1], [8 8 8 8])\n",
      "\tEl gradiente de 36485 proviene de (grad_origin): 39106 count: 2\n",
      "\tpor tanto el contador de 36485 se reduce a 1 para su hijo 39106\n",
      "\tTensor 36485 has creators? True \n",
      "\tAll children grads from 36485 accounted for is (cnt != 0) False \n",
      "\tHas grad origin? False \n",
      "\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t True and ( False or False ) => False\n",
      "\n",
      "\tbackward call from creator[1] 36485\n",
      "\tbackward(36485, [1 1 1 1], [8 8 8 8])\n",
      "\tEl gradiente de 36485 proviene de (grad_origin): 39106 count: 1\n",
      "\tpor tanto el contador de 36485 se reduce a 0 para su hijo 39106\n",
      "\tTensor 36485 has creators? True \n",
      "\tAll children grads from 36485 accounted for is (cnt != 0) True \n",
      "\tHas grad origin? False \n",
      "\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t True and ( True or False ) => True\n",
      "\t36485 creators are:\n",
      "\tcreator 35424 : [2 2 2 2] creator 35424 : [2 2 2 2]\n",
      "\t\tbackward call from creator[0]: 35424\n",
      "\t\tbackward(35424, [2 2 2 2], [4 4 4 4])\n",
      "\t\tEl gradiente de 35424 proviene de (grad_origin): 36485 count: 2\n",
      "\t\tpor tanto el contador de 35424 se reduce a 1 para su hijo 36485\n",
      "\t\tTensor 35424 has creators? False \n",
      "\t\tAll children grads from 35424 accounted for is (cnt != 0) False \n",
      "\t\tHas grad origin? False \n",
      "\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t False and ( False or False ) => False\n",
      "\n",
      "\t\tbackward call from creator[1] 35424\n",
      "\t\tbackward(35424, [2 2 2 2], [4 4 4 4])\n",
      "\t\tEl gradiente de 35424 proviene de (grad_origin): 36485 count: 1\n",
      "\t\tpor tanto el contador de 35424 se reduce a 0 para su hijo 36485\n",
      "\t\tTensor 35424 has creators? False \n",
      "\t\tAll children grads from 35424 accounted for is (cnt != 0) True \n",
      "\t\tHas grad origin? False \n",
      "\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t False and ( True or False ) => False\n",
      "\n",
      "x gradient data: [4 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "x = Tensor([2,2,2,2], autograd=True)\n",
    "print('y = x + x')\n",
    "y = x + x\n",
    "print('z = y + y')\n",
    "z = y + y\n",
    "print()\n",
    "\n",
    "print('x id:',x.id)\n",
    "for hijo, cnt in x.children.items():\n",
    "    print(' hijo:', hijo, 'count', cnt)\n",
    "    \n",
    "print('y id:', y.id)\n",
    "for hijo, cnt in y.children.items():\n",
    "    print(' hijo:', hijo, 'count', cnt)\n",
    "    \n",
    "print('z id:', z.id, '\\n')\n",
    "z.backward(Tensor([1,1,1,1]))\n",
    "print('\\nx gradient data:',x.grad.data)\n",
    "# z.backward(Tensor([1,1,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d = a + b\n",
      "  new tensor id is 39565\n",
      "e = b + c\n",
      "  new tensor id is 30815\n",
      "f = d + e\n",
      "  new tensor id is 74828\n",
      "\n",
      "a id: 65521\n",
      "\thijo: 39565 count 1\n",
      "b id: 59859\n",
      "\thijo: 39565 count 1\n",
      "\thijo: 30815 count 1\n",
      "c id: 55699\n",
      "\thijo: 30815 count 1\n",
      "d id: 39565\n",
      "\thijo: 74828 count 1\n",
      "e id: 30815\n",
      "\thijo: 74828 count 1\n",
      "f id: 74828 \n",
      "\n",
      "backward(74828, [1 1 1 1 1], None)\n",
      "Tensor 74828 has creators? True \n",
      "All children grads from 74828 accounted for is (cnt != 0) True \n",
      "Has grad origin? True \n",
      "Has creators and (children grads accounted or grad no grad origin) \n",
      " True and ( True or True ) => True\n",
      "74828 creators are:\n",
      "creator 39565 : [3 4 5 6 7] creator 30815 : [7 6 5 4 3]\n",
      "\tbackward call from creator[0]: 39565\n",
      "\tbackward(39565, [1 1 1 1 1], [10 10 10 10 10])\n",
      "\tEl gradiente de 39565 proviene de (grad_origin): 74828 count: 1\n",
      "\tpor tanto el contador de 39565 se reduce a 0 para su hijo 74828\n",
      "\tTensor 39565 has creators? True \n",
      "\tAll children grads from 39565 accounted for is (cnt != 0) True \n",
      "\tHas grad origin? False \n",
      "\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t True and ( True or False ) => True\n",
      "\t39565 creators are:\n",
      "\tcreator 65521 : [1 2 3 4 5] creator 59859 : [2 2 2 2 2]\n",
      "\t\tbackward call from creator[0]: 65521\n",
      "\t\tbackward(65521, [1 1 1 1 1], [3 4 5 6 7])\n",
      "\t\tEl gradiente de 65521 proviene de (grad_origin): 39565 count: 1\n",
      "\t\tpor tanto el contador de 65521 se reduce a 0 para su hijo 39565\n",
      "\t\tTensor 65521 has creators? False \n",
      "\t\tAll children grads from 65521 accounted for is (cnt != 0) True \n",
      "\t\tHas grad origin? False \n",
      "\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t False and ( True or False ) => False\n",
      "\n",
      "\t\tbackward call from creator[1] 65521\n",
      "\t\tbackward(59859, [1 1 1 1 1], [3 4 5 6 7])\n",
      "\t\tEl gradiente de 59859 proviene de (grad_origin): 39565 count: 1\n",
      "\t\tpor tanto el contador de 59859 se reduce a 0 para su hijo 39565\n",
      "\t\tTensor 59859 has creators? False \n",
      "\t\tAll children grads from 59859 accounted for is (cnt != 0) False \n",
      "\t\tHas grad origin? False \n",
      "\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t False and ( False or False ) => False\n",
      "\n",
      "\tbackward call from creator[1] 39565\n",
      "\tbackward(30815, [1 1 1 1 1], [10 10 10 10 10])\n",
      "\tEl gradiente de 30815 proviene de (grad_origin): 74828 count: 1\n",
      "\tpor tanto el contador de 30815 se reduce a 0 para su hijo 74828\n",
      "\tTensor 30815 has creators? True \n",
      "\tAll children grads from 30815 accounted for is (cnt != 0) True \n",
      "\tHas grad origin? False \n",
      "\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t True and ( True or False ) => True\n",
      "\t30815 creators are:\n",
      "\tcreator 59859 : [2 2 2 2 2] creator 55699 : [5 4 3 2 1]\n",
      "\t\tbackward call from creator[0]: 59859\n",
      "\t\tbackward(59859, [1 1 1 1 1], [7 6 5 4 3])\n",
      "\t\tEl gradiente de 59859 proviene de (grad_origin): 30815 count: 1\n",
      "\t\tpor tanto el contador de 59859 se reduce a 0 para su hijo 30815\n",
      "\t\tTensor 59859 has creators? False \n",
      "\t\tAll children grads from 59859 accounted for is (cnt != 0) True \n",
      "\t\tHas grad origin? False \n",
      "\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t False and ( True or False ) => False\n",
      "\n",
      "\t\tbackward call from creator[1] 59859\n",
      "\t\tbackward(55699, [1 1 1 1 1], [7 6 5 4 3])\n",
      "\t\tEl gradiente de 55699 proviene de (grad_origin): 30815 count: 1\n",
      "\t\tpor tanto el contador de 55699 se reduce a 0 para su hijo 30815\n",
      "\t\tTensor 55699 has creators? False \n",
      "\t\tAll children grads from 55699 accounted for is (cnt != 0) True \n",
      "\t\tHas grad origin? False \n",
      "\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t False and ( True or False ) => False\n",
      "[ True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "a = Tensor([1,2,3,4,5], autograd=True)\n",
    "b = Tensor([2,2,2,2,2], autograd=True)\n",
    "c = Tensor([5,4,3,2,1], autograd=True)\n",
    "\n",
    "print('d = a + b')\n",
    "d = a + b\n",
    "print('e = b + c')\n",
    "e = b + c\n",
    "print('f = d + e')\n",
    "f = d + e\n",
    "print()\n",
    "\n",
    "print('a id:',a.id)\n",
    "for hijo, cnt in a.children.items():\n",
    "    print('\\thijo:', hijo, 'count', cnt)\n",
    "    \n",
    "print('b id:', b.id)\n",
    "for hijo, cnt in b.children.items():\n",
    "    print('\\thijo:', hijo, 'count', cnt)\n",
    "    \n",
    "print('c id:',c.id)\n",
    "for hijo, cnt in c.children.items():\n",
    "    print('\\thijo:', hijo, 'count', cnt)\n",
    "    \n",
    "print('d id:', d.id)\n",
    "for hijo, cnt in d.children.items():\n",
    "    print('\\thijo:', hijo, 'count', cnt)\n",
    "\n",
    "print('e id:', e.id)\n",
    "for hijo, cnt in e.children.items():\n",
    "    print('\\thijo:', hijo, 'count', cnt)\n",
    "    \n",
    "print('f id:', f.id, '\\n')\n",
    "\n",
    "f.backward(Tensor(np.array([1,1,1,1,1])))\n",
    "print(b.grad.data == np.array([2,2,2,2,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x3 = x1 + x2\n",
      "  new tensor id is 7181\n",
      "x4 = x1 + x2\n",
      "  new tensor id is 56634\n",
      "x5 = x1+ x2 + x3 + x4\n",
      "  new tensor id is 28334\n",
      "  new tensor id is 45990\n",
      "  new tensor id is 92166\n",
      "\n",
      "x1 id: 54166\n",
      "\thijo: 7181 count 1\n",
      "\thijo: 56634 count 1\n",
      "\thijo: 28334 count 1\n",
      "x2 id: 50546\n",
      "\thijo: 7181 count 1\n",
      "\thijo: 56634 count 1\n",
      "\thijo: 28334 count 1\n",
      "x3 id: 7181\n",
      "\thijo: 45990 count 1\n",
      "x4 id: 56634\n",
      "\thijo: 92166 count 1\n",
      "x5 id: 92166 \n",
      "\n",
      "backward(92166, [1 1 1 1], None)\n",
      "Tensor 92166 has creators? True \n",
      "All children grads from 92166 accounted for is (cnt != 0) True \n",
      "Has grad origin? True \n",
      "Has creators and (children grads accounted or grad no grad origin) \n",
      " True and ( True or True ) => True\n",
      "92166 creators are:\n",
      "creator 45990 : [4 4 4 4] creator 56634 : [2 2 2 2]\n",
      "\tbackward call from creator[0]: 45990\n",
      "\tbackward(45990, [1 1 1 1], [6 6 6 6])\n",
      "\tEl gradiente de 45990 proviene de (grad_origin): 92166 count: 1\n",
      "\tpor tanto el contador de 45990 se reduce a 0 para su hijo 92166\n",
      "\tTensor 45990 has creators? True \n",
      "\tAll children grads from 45990 accounted for is (cnt != 0) True \n",
      "\tHas grad origin? False \n",
      "\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t True and ( True or False ) => True\n",
      "\t45990 creators are:\n",
      "\tcreator 28334 : [2 2 2 2] creator 7181 : [2 2 2 2]\n",
      "\t\tbackward call from creator[0]: 28334\n",
      "\t\tbackward(28334, [1 1 1 1], [4 4 4 4])\n",
      "\t\tEl gradiente de 28334 proviene de (grad_origin): 45990 count: 1\n",
      "\t\tpor tanto el contador de 28334 se reduce a 0 para su hijo 45990\n",
      "\t\tTensor 28334 has creators? True \n",
      "\t\tAll children grads from 28334 accounted for is (cnt != 0) True \n",
      "\t\tHas grad origin? False \n",
      "\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t True and ( True or False ) => True\n",
      "\t\t28334 creators are:\n",
      "\t\tcreator 54166 : [1 1 1 1] creator 50546 : [1 1 1 1]\n",
      "\t\t\tbackward call from creator[0]: 54166\n",
      "\t\t\tbackward(54166, [1 1 1 1], [2 2 2 2])\n",
      "\t\t\tEl gradiente de 54166 proviene de (grad_origin): 28334 count: 1\n",
      "\t\t\tpor tanto el contador de 54166 se reduce a 0 para su hijo 28334\n",
      "\t\t\tTensor 54166 has creators? False \n",
      "\t\t\tAll children grads from 54166 accounted for is (cnt != 0) False \n",
      "\t\t\tHas grad origin? False \n",
      "\t\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t\t False and ( False or False ) => False\n",
      "\n",
      "\t\t\tbackward call from creator[1] 54166\n",
      "\t\t\tbackward(50546, [1 1 1 1], [2 2 2 2])\n",
      "\t\t\tEl gradiente de 50546 proviene de (grad_origin): 28334 count: 1\n",
      "\t\t\tpor tanto el contador de 50546 se reduce a 0 para su hijo 28334\n",
      "\t\t\tTensor 50546 has creators? False \n",
      "\t\t\tAll children grads from 50546 accounted for is (cnt != 0) False \n",
      "\t\t\tHas grad origin? False \n",
      "\t\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t\t False and ( False or False ) => False\n",
      "\n",
      "\t\tbackward call from creator[1] 28334\n",
      "\t\tbackward(7181, [1 1 1 1], [4 4 4 4])\n",
      "\t\tEl gradiente de 7181 proviene de (grad_origin): 45990 count: 1\n",
      "\t\tpor tanto el contador de 7181 se reduce a 0 para su hijo 45990\n",
      "\t\tTensor 7181 has creators? True \n",
      "\t\tAll children grads from 7181 accounted for is (cnt != 0) True \n",
      "\t\tHas grad origin? False \n",
      "\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t True and ( True or False ) => True\n",
      "\t\t7181 creators are:\n",
      "\t\tcreator 54166 : [1 1 1 1] creator 50546 : [1 1 1 1]\n",
      "\t\t\tbackward call from creator[0]: 54166\n",
      "\t\t\tbackward(54166, [1 1 1 1], [2 2 2 2])\n",
      "\t\t\tEl gradiente de 54166 proviene de (grad_origin): 7181 count: 1\n",
      "\t\t\tpor tanto el contador de 54166 se reduce a 0 para su hijo 7181\n",
      "\t\t\tTensor 54166 has creators? False \n",
      "\t\t\tAll children grads from 54166 accounted for is (cnt != 0) False \n",
      "\t\t\tHas grad origin? False \n",
      "\t\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t\t False and ( False or False ) => False\n",
      "\n",
      "\t\t\tbackward call from creator[1] 54166\n",
      "\t\t\tbackward(50546, [1 1 1 1], [2 2 2 2])\n",
      "\t\t\tEl gradiente de 50546 proviene de (grad_origin): 7181 count: 1\n",
      "\t\t\tpor tanto el contador de 50546 se reduce a 0 para su hijo 7181\n",
      "\t\t\tTensor 50546 has creators? False \n",
      "\t\t\tAll children grads from 50546 accounted for is (cnt != 0) False \n",
      "\t\t\tHas grad origin? False \n",
      "\t\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t\t False and ( False or False ) => False\n",
      "\n",
      "\tbackward call from creator[1] 45990\n",
      "\tbackward(56634, [1 1 1 1], [6 6 6 6])\n",
      "\tEl gradiente de 56634 proviene de (grad_origin): 92166 count: 1\n",
      "\tpor tanto el contador de 56634 se reduce a 0 para su hijo 92166\n",
      "\tTensor 56634 has creators? True \n",
      "\tAll children grads from 56634 accounted for is (cnt != 0) True \n",
      "\tHas grad origin? False \n",
      "\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t True and ( True or False ) => True\n",
      "\t56634 creators are:\n",
      "\tcreator 54166 : [1 1 1 1] creator 50546 : [1 1 1 1]\n",
      "\t\tbackward call from creator[0]: 54166\n",
      "\t\tbackward(54166, [1 1 1 1], [2 2 2 2])\n",
      "\t\tEl gradiente de 54166 proviene de (grad_origin): 56634 count: 1\n",
      "\t\tpor tanto el contador de 54166 se reduce a 0 para su hijo 56634\n",
      "\t\tTensor 54166 has creators? False \n",
      "\t\tAll children grads from 54166 accounted for is (cnt != 0) True \n",
      "\t\tHas grad origin? False \n",
      "\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t False and ( True or False ) => False\n",
      "\n",
      "\t\tbackward call from creator[1] 54166\n",
      "\t\tbackward(50546, [1 1 1 1], [2 2 2 2])\n",
      "\t\tEl gradiente de 50546 proviene de (grad_origin): 56634 count: 1\n",
      "\t\tpor tanto el contador de 50546 se reduce a 0 para su hijo 56634\n",
      "\t\tTensor 50546 has creators? False \n",
      "\t\tAll children grads from 50546 accounted for is (cnt != 0) True \n",
      "\t\tHas grad origin? False \n",
      "\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t False and ( True or False ) => False\n"
     ]
    }
   ],
   "source": [
    "x1 = Tensor([1,1,1,1], autograd=True)\n",
    "x2 = Tensor([1,1,1,1], autograd=True)\n",
    "\n",
    "print('x3 = x1 + x2')\n",
    "x3 = x1 + x2\n",
    "print('x4 = x1 + x2')\n",
    "x4 = x1 + x2\n",
    "print('x5 = x1+ x2 + x3 + x4')\n",
    "x5 = x1+ x2 + x3 + x4\n",
    "print()\n",
    "\n",
    "print('x1 id:',x1.id)\n",
    "for hijo, cnt in x1.children.items():\n",
    "    print('\\thijo:', hijo, 'count', cnt)\n",
    "    \n",
    "print('x2 id:', x2.id)\n",
    "for hijo, cnt in x2.children.items():\n",
    "    print('\\thijo:', hijo, 'count', cnt)\n",
    "    \n",
    "print('x3 id:',x3.id)\n",
    "for hijo, cnt in x3.children.items():\n",
    "    print('\\thijo:', hijo, 'count', cnt)\n",
    "    \n",
    "print('x4 id:', x4.id)\n",
    "for hijo, cnt in x4.children.items():\n",
    "    print('\\thijo:', hijo, 'count', cnt)\n",
    "    \n",
    "print('x5 id:', x5.id, '\\n')\n",
    "\n",
    "x5.backward(Tensor([1,1,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = x + x + x + x\n",
      "  new tensor id is 88879\n",
      "  new tensor id is 57091\n",
      "  new tensor id is 62010\n",
      "z = y + y\n",
      "  new tensor id is 83512\n",
      "\n",
      "x id: 81129\n",
      " hijo: 88879 count 2\n",
      " hijo: 57091 count 1\n",
      " hijo: 62010 count 1\n",
      "y id: 62010\n",
      " hijo: 83512 count 2\n",
      "z id: 83512 \n",
      "\n",
      "backward(83512, [1 1 1 1], None)\n",
      "Tensor 83512 has creators? True \n",
      "All children grads from 83512 accounted for is (cnt != 0) True \n",
      "Has grad origin? True \n",
      "Has creators and (children grads accounted or grad no grad origin) \n",
      " True and ( True or True ) => True\n",
      "83512 creators are:\n",
      "creator 62010 : [8 8 8 8] creator 62010 : [8 8 8 8]\n",
      "\tbackward call from creator[0]: 62010\n",
      "\tbackward(62010, [1 1 1 1], [16 16 16 16])\n",
      "\tEl gradiente de 62010 proviene de (grad_origin): 83512 count: 2\n",
      "\tpor tanto el contador de 62010 se reduce a 1 para su hijo 83512\n",
      "\tTensor 62010 has creators? True \n",
      "\tAll children grads from 62010 accounted for is (cnt != 0) False \n",
      "\tHas grad origin? False \n",
      "\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t True and ( False or False ) => False\n",
      "\n",
      "\tbackward call from creator[1] 62010\n",
      "\tbackward(62010, [1 1 1 1], [16 16 16 16])\n",
      "\tEl gradiente de 62010 proviene de (grad_origin): 83512 count: 1\n",
      "\tpor tanto el contador de 62010 se reduce a 0 para su hijo 83512\n",
      "\tTensor 62010 has creators? True \n",
      "\tAll children grads from 62010 accounted for is (cnt != 0) True \n",
      "\tHas grad origin? False \n",
      "\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t True and ( True or False ) => True\n",
      "\t62010 creators are:\n",
      "\tcreator 57091 : [6 6 6 6] creator 81129 : [2 2 2 2]\n",
      "\t\tbackward call from creator[0]: 57091\n",
      "\t\tbackward(57091, [2 2 2 2], [8 8 8 8])\n",
      "\t\tEl gradiente de 57091 proviene de (grad_origin): 62010 count: 1\n",
      "\t\tpor tanto el contador de 57091 se reduce a 0 para su hijo 62010\n",
      "\t\tTensor 57091 has creators? True \n",
      "\t\tAll children grads from 57091 accounted for is (cnt != 0) True \n",
      "\t\tHas grad origin? False \n",
      "\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t True and ( True or False ) => True\n",
      "\t\t57091 creators are:\n",
      "\t\tcreator 88879 : [4 4 4 4] creator 81129 : [2 2 2 2]\n",
      "\t\t\tbackward call from creator[0]: 88879\n",
      "\t\t\tbackward(88879, [2 2 2 2], [6 6 6 6])\n",
      "\t\t\tEl gradiente de 88879 proviene de (grad_origin): 57091 count: 1\n",
      "\t\t\tpor tanto el contador de 88879 se reduce a 0 para su hijo 57091\n",
      "\t\t\tTensor 88879 has creators? True \n",
      "\t\t\tAll children grads from 88879 accounted for is (cnt != 0) True \n",
      "\t\t\tHas grad origin? False \n",
      "\t\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t\t True and ( True or False ) => True\n",
      "\t\t\t88879 creators are:\n",
      "\t\t\tcreator 81129 : [2 2 2 2] creator 81129 : [2 2 2 2]\n",
      "\t\t\t\tbackward call from creator[0]: 81129\n",
      "\t\t\t\tbackward(81129, [2 2 2 2], [4 4 4 4])\n",
      "\t\t\t\tEl gradiente de 81129 proviene de (grad_origin): 88879 count: 2\n",
      "\t\t\t\tpor tanto el contador de 81129 se reduce a 1 para su hijo 88879\n",
      "\t\t\t\tTensor 81129 has creators? False \n",
      "\t\t\t\tAll children grads from 81129 accounted for is (cnt != 0) False \n",
      "\t\t\t\tHas grad origin? False \n",
      "\t\t\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t\t\t False and ( False or False ) => False\n",
      "\n",
      "\t\t\t\tbackward call from creator[1] 81129\n",
      "\t\t\t\tbackward(81129, [2 2 2 2], [4 4 4 4])\n",
      "\t\t\t\tEl gradiente de 81129 proviene de (grad_origin): 88879 count: 1\n",
      "\t\t\t\tpor tanto el contador de 81129 se reduce a 0 para su hijo 88879\n",
      "\t\t\t\tTensor 81129 has creators? False \n",
      "\t\t\t\tAll children grads from 81129 accounted for is (cnt != 0) False \n",
      "\t\t\t\tHas grad origin? False \n",
      "\t\t\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t\t\t False and ( False or False ) => False\n",
      "\n",
      "\t\t\tbackward call from creator[1] 88879\n",
      "\t\t\tbackward(81129, [2 2 2 2], [6 6 6 6])\n",
      "\t\t\tEl gradiente de 81129 proviene de (grad_origin): 57091 count: 1\n",
      "\t\t\tpor tanto el contador de 81129 se reduce a 0 para su hijo 57091\n",
      "\t\t\tTensor 81129 has creators? False \n",
      "\t\t\tAll children grads from 81129 accounted for is (cnt != 0) False \n",
      "\t\t\tHas grad origin? False \n",
      "\t\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t\t False and ( False or False ) => False\n",
      "\n",
      "\t\tbackward call from creator[1] 57091\n",
      "\t\tbackward(81129, [2 2 2 2], [8 8 8 8])\n",
      "\t\tEl gradiente de 81129 proviene de (grad_origin): 62010 count: 1\n",
      "\t\tpor tanto el contador de 81129 se reduce a 0 para su hijo 62010\n",
      "\t\tTensor 81129 has creators? False \n",
      "\t\tAll children grads from 81129 accounted for is (cnt != 0) True \n",
      "\t\tHas grad origin? False \n",
      "\t\tHas creators and (children grads accounted or grad no grad origin) \n",
      "\t\t False and ( True or False ) => False\n",
      "\n",
      "x gradient data: [8 8 8 8]\n"
     ]
    }
   ],
   "source": [
    "x = Tensor([2,2,2,2], autograd=True)\n",
    "\n",
    "print('y = x + x + x + x')\n",
    "y = x + x + x + x\n",
    "print('z = y + y')\n",
    "z = y + y\n",
    "print()\n",
    "\n",
    "print('x id:',x.id)\n",
    "for hijo, cnt in x.children.items():\n",
    "    print(' hijo:', hijo, 'count', cnt)\n",
    "    \n",
    "print('y id:', y.id)\n",
    "for hijo, cnt in y.children.items():\n",
    "    print(' hijo:', hijo, 'count', cnt)\n",
    "    \n",
    "print('z id:', z.id, '\\n')\n",
    "\n",
    "z.backward(Tensor([1,1,1,1]))\n",
    "print('\\nx gradient data:',x.grad.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
