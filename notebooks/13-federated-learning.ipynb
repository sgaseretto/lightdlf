{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a Federated Learning o Aprendizaje Federado\n",
    "\n",
    "## Problemas de privacidad al usar Deep Learning y otras tecnicas de Machine Learning\n",
    "\n",
    "Es sabido que las redes neuronales o ```deep learning``` como se lo conoce ahora es un sub-area del campo de ```Machine Learning```. Todo este grupo de algoritmos se caracterisa del resto de las otras áreas de la ```Inteligencia Artificial``` en que hecho de que su principal caracteristica es la capacidad que tienen de aprender utilizando datos, en lugar de usar reglas predefinidas. Pero muchas veces, los datos sobre los que se quiere crear un modelo de machine learning son datos muy personales y privados. Los mejores y más útiles modelos interactúan con los datos más personales de las personas y decirnos cosas sobre nosotros que hubiesen sido dificiles de saber de otra manera. Pero al mismo tiempo dar toda esta información requiere que confiemos en quien va a almacenar estos datos y que los cuidará para protejer nuestra privacidad, lo cual no siempre ocurre. Ejemplos de esto son:\n",
    "- **Aplicaciones en Medicina**: machine learning puede ayudar a mejorar dramáticamente diagnostico de enfermedades, como detección de tumores en imagenes de MRI, detectar con tiempo retinopatía diabética en imagenes de retina, detección de cancer en imagenes de melanoma, entre varias otras aplicaciónes más. Pero este tipo de datos son bastante sensibles ya que son datos de los pacientes, una filtración de este tipo de información sería muy grave.\n",
    "- **Recomendaciones**: ya sea recomendacion de productos, contenido o publicidad, estos modelos buscan personalizar la interacción de los usuarios en los servicios que están utilizando. Mientras más información personal del usuario sea posible de obtener para el modelo de recomendación, mucho mejor será la experiencia del usuario final, que recibirá recomendaciones más significativas. En el 2018 se reveló que una empresa de Cambridge utilizó datos personales de varios usuarios de Facebook para crear un perfil psicológico de cada uno y poder crear campañas de desinformación a través de facebook, que recomendaba anunciós con discursos de odio, con  para influenciar campañas electorales en el 2016 en Estados Unidos, influenciar la salida de Inglaterra de la EU (Brexit) entre varios otros escandalos.\n",
    "    - [Facebook–Cambridge Analytica data scandal](https://www.wikiwand.com/en/Facebook%E2%80%93Cambridge_Analytica_data_scandal)\n",
    "- **Credit Scoring**: modelos para saber que tan buenos pagadores de prestamos somos. Pueden utilizar informacion personal como historial crediticio, gastos varios y datos demograficos. Esta es información sensible que no querriamos que corra el riesgo de ser revelada a personas mal intencionadas. Por ejemplo, en el 2017 se reveló que Equifax ,una de las más grandes empresas que otorga credit scorings, entre varios otros servicios utilizando información personal de millones de personas, tuvo un breach enorme de información sensible de millones de personas.\n",
    "    - [Equifax Security Failing](https://www.wikiwand.com/en/Equifax#/Security_failings)\n",
    "    - [Equifax Breach: What Happened](https://www.csoonline.com/article/3444488/equifax-data-breach-faq-what-happened-who-was-affected-what-was-the-impact.html)\n",
    "    \n",
    "Ya que los datos son el recurso primordial para modelos como las redes neuronales, y los casos de uso más significativos de los mismos requiere que interactúen con datos personales, es necesario encontrar una manera de acceder a los mismos sin correr el riesgo de violar la privacidad de las personas.\n",
    "\n",
    "> Que pasaría si en lugar de acumular datos privados en un lugar centralizado para entrenar un modelo de deep learning, pudieramos enviar el modelo a donde se generan los datos y entrenar el modelo desde ahí, evitando así tener un solo punto de fallo desde el cual pueda ocurrir un ```breach``` de datos.\n",
    "\n",
    "Esto significa que:\n",
    "- Tecnicamente para poder participar en el entrenamiento de un modelo de deep learning, los usuarios no necesitan enviar sus datos a nadie, permitiendo así entrenar modelos valiosos con datos de salud, financieros, etc.\n",
    "- Personas y empresas que antes no podían compartir sus datos por cuestiones legales igual podrán generar valor gracias a ellos.\n",
    "\n",
    "## Federated Learning\n",
    "\n",
    "La premisa federated learning es que multiples datasets contienen información que es útil para resolver un problema, pero es dificil poder acceder a estos datasets en cantidades lo suficientemente grandes como para entrenar un modelo de deep learning que generalice lo suficientemente bien.\n",
    "\n",
    "Si bien el dataset puede tener suficiente informacion para entrenar un modelo de deep learning, la principal preocupación es que este también pueda contener información que no tenga relación con el aprendizaje del modelo, pero que pueda causar daños a alguien si es revelada. \n",
    "\n",
    "```Federated Learning``` se trata de enviar el modelo a un entorno seguro y aprender como resolver el problema sin la necesidad de mover los datos a ninguna parte. En este notebook veremos un ejemplo simple de ```federated learning.```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "- [Federated Learning: Collaborative Machine Learning without Centralized Training Data](https://ai.googleblog.com/2017/04/federated-learning-collaborative.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
